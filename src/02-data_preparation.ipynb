{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aedab6a",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07869300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e1915",
   "metadata": {},
   "source": [
    "## 1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de6c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User_ID  Calories\n",
      "0  14733363     231.0\n",
      "1  14861698      66.0\n",
      "2  11179863      26.0\n",
      "3  16180408      71.0\n",
      "4  17771927      35.0\n",
      "    User_ID  Gender  Age  Height  Weight  Duration  Heart_Rate  Body_Temp\n",
      "0  14733363    male   68   190.0    94.0      29.0       105.0       40.8\n",
      "1  14861698  female   20   166.0    60.0      14.0        94.0       40.3\n",
      "2  11179863    male   69   179.0    79.0       5.0        88.0       38.7\n",
      "3  16180408  female   34   179.0    71.0      13.0       100.0       40.5\n",
      "4  17771927  female   27   154.0    58.0      10.0        81.0       39.8\n"
     ]
    }
   ],
   "source": [
    "calories=pd.read_csv('../data/raw/calories.csv')\n",
    "exercise=pd.read_csv('../data/raw/exercise.csv')\n",
    "\n",
    "print(calories.head())\n",
    "print(exercise.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f32272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User_ID  Calories  Gender  Age  Height  Weight  Duration  Heart_Rate  \\\n",
      "0  14733363     231.0    male   68   190.0    94.0      29.0       105.0   \n",
      "1  14861698      66.0  female   20   166.0    60.0      14.0        94.0   \n",
      "2  11179863      26.0    male   69   179.0    79.0       5.0        88.0   \n",
      "3  16180408      71.0  female   34   179.0    71.0      13.0       100.0   \n",
      "4  17771927      35.0  female   27   154.0    58.0      10.0        81.0   \n",
      "\n",
      "   Body_Temp  \n",
      "0       40.8  \n",
      "1       40.3  \n",
      "2       38.7  \n",
      "3       40.5  \n",
      "4       39.8  \n"
     ]
    }
   ],
   "source": [
    "# Merge datasets on 'User_ID'\n",
    "newData_df = pd.merge(calories, exercise, on='User_ID', how='inner')  # Using inner join\n",
    "\n",
    "# Preview merged data\n",
    "print(newData_df.head())\n",
    "\n",
    "# Save merged dataset\n",
    "newData_df.to_csv('../data/raw/mergedNew_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832b038",
   "metadata": {},
   "source": [
    "## 2. Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c4bce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   User_ID     15000 non-null  int64  \n",
      " 1   Calories    15000 non-null  float64\n",
      " 2   Gender      15000 non-null  object \n",
      " 3   Age         15000 non-null  int64  \n",
      " 4   Height      15000 non-null  float64\n",
      " 5   Weight      15000 non-null  float64\n",
      " 6   Duration    15000 non-null  float64\n",
      " 7   Heart_Rate  15000 non-null  float64\n",
      " 8   Body_Temp   15000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "newData_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9277c6",
   "metadata": {},
   "source": [
    "Given some self-report biometrics from the user we will build two models that do the following depending on user input:\n",
    "\n",
    "1. Take workout duration and predict calorie burn for each workout type (i.e. 'I am going to work out for X minutes, how many calories will I burn?').\n",
    "2. Take calorie burn and predict duration for each workout type (i.e., 'I want to burn X calories, how long do I need to work out for?').\n",
    "\n",
    "Both models will share a set of input 'biometric' features. These must be things the user is likely to know about themselves. People probably know their weight and age, but probably don't know their VO2 max.\n",
    "\n",
    "The models will differ in one of their input features and their output:\n",
    "\n",
    "1. `calorie_model` needs to take workout duration + biometrics as input features and predict calories burned.\n",
    "2. `time_model` needs to take calories burned + biometrics as input features and predict workout duration. \n",
    "\n",
    "We will use dictionaries to keep everything organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59769762",
   "metadata": {},
   "outputs": [],
   "source": [
    "biometric_features=[\n",
    "    'Age', 'Gender', 'Height', 'Weight'\n",
    "]\n",
    "\n",
    "input_features={\n",
    "    'calorie_model': ['Duration'] + biometric_features,\n",
    "    'time_model': ['Calories Burned'] + biometric_features\n",
    "}\n",
    "\n",
    "output_features={\n",
    "    'calorie_model': 'Calories',\n",
    "    'time_model': 'Duration'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620fd11",
   "metadata": {},
   "source": [
    "## 3. Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf068d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User_ID  Calories  Gender  Age  Height  Weight  Duration  Heart_Rate  \\\n",
      "0  14733363     231.0     0.0   68   190.0    94.0      29.0       105.0   \n",
      "1  14861698      66.0     1.0   20   166.0    60.0      14.0        94.0   \n",
      "2  11179863      26.0     0.0   69   179.0    79.0       5.0        88.0   \n",
      "3  16180408      71.0     1.0   34   179.0    71.0      13.0       100.0   \n",
      "4  17771927      35.0     1.0   27   154.0    58.0      10.0        81.0   \n",
      "\n",
      "   Body_Temp  \n",
      "0       40.8  \n",
      "1       40.3  \n",
      "2       38.7  \n",
      "3       40.5  \n",
      "4       39.8  \n"
     ]
    }
   ],
   "source": [
    "# Your code here... I recommend sklearn's OrdinalEncoder to start with because it will let us keep the \n",
    "# number/names of features constant. We can experiment with improving encoding later if we have time.\n",
    "\n",
    "categorical_features=['Gender']\n",
    "\n",
    "# Extract unique values from categorical features\n",
    "categories_list = [\n",
    "    newData_df[\"Gender\"].unique().tolist(),\n",
    "]\n",
    "\n",
    "# Apply dynamic categories to OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=categories_list)\n",
    "\n",
    "# Apply encoding to categorical columns\n",
    "df_encoded = newData_df.copy()  # Keep original dataframe\n",
    "df_encoded[categorical_features] = encoder.fit_transform(newData_df[categorical_features])\n",
    "\n",
    "print(df_encoded.head())  # Check encoded values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a7f42",
   "metadata": {},
   "source": [
    "## 4. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943ad6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (12000, 9)\n",
      "Test Data Shape: (3000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Your code here....\n",
    "def split_data(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"Splits the dataset into train_df and test_df.\"\"\"\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Apply the split\n",
    "train_df, test_df = split_data(df_encoded)\n",
    "\n",
    "# Confirm the split sizes\n",
    "print(f\"Train Data Shape: {train_df.shape}\")\n",
    "print(f\"Test Data Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75ad5d",
   "metadata": {},
   "source": [
    "## 5. Save assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bbc6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature information\n",
    "with open('../data/biometric_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(biometric_features, output_file)\n",
    "\n",
    "with open('../data/input_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(input_features, output_file)\n",
    "\n",
    "with open('../data/output_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(output_features, output_file)\n",
    "\n",
    "with open('../data/categorical_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(categorical_features, output_file)\n",
    "\n",
    "# Data\n",
    "Path('../data/processed').mkdir(exist_ok=True)\n",
    "\n",
    "with open('../data/processed/all.pkl', 'wb') as output_file:\n",
    "    pickle.dump(newData_df, output_file)\n",
    "\n",
    "with open('../data/processed/train.pkl', 'wb') as output_file:\n",
    "    pickle.dump(train_df, output_file)\n",
    "\n",
    "with open('../data/processed/test.pkl', 'wb') as output_file:\n",
    "    pickle.dump(test_df, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aedab6a",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07869300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e1915",
   "metadata": {},
   "source": [
    "## 1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de6c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv('../data/raw/workout_fitness_tracker_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832b038",
   "metadata": {},
   "source": [
    "## 2. Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c4bce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   User ID                   10000 non-null  int64  \n",
      " 1   Age                       10000 non-null  int64  \n",
      " 2   Gender                    10000 non-null  object \n",
      " 3   Height (cm)               10000 non-null  int64  \n",
      " 4   Weight (kg)               10000 non-null  int64  \n",
      " 5   Workout Type              10000 non-null  object \n",
      " 6   Workout Duration (mins)   10000 non-null  int64  \n",
      " 7   Calories Burned           10000 non-null  int64  \n",
      " 8   Heart Rate (bpm)          10000 non-null  int64  \n",
      " 9   Steps Taken               10000 non-null  int64  \n",
      " 10  Distance (km)             10000 non-null  float64\n",
      " 11  Workout Intensity         10000 non-null  object \n",
      " 12  Sleep Hours               10000 non-null  float64\n",
      " 13  Water Intake (liters)     10000 non-null  float64\n",
      " 14  Daily Calories Intake     10000 non-null  int64  \n",
      " 15  Resting Heart Rate (bpm)  10000 non-null  int64  \n",
      " 16  VO2 Max                   10000 non-null  float64\n",
      " 17  Body Fat (%)              10000 non-null  float64\n",
      " 18  Mood Before Workout       10000 non-null  object \n",
      " 19  Mood After Workout        10000 non-null  object \n",
      "dtypes: float64(5), int64(10), object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9277c6",
   "metadata": {},
   "source": [
    "Given some self-report biometrics from the user we will build two models that do the following depending on user input:\n",
    "\n",
    "1. Take workout duration and predict calorie burn for each workout type (i.e. 'I am going to work out for X minutes, how many calories will I burn?').\n",
    "2. Take calorie burn and predict duration for each workout type (i.e., 'I want to burn X calories, how long do I need to work out for?').\n",
    "\n",
    "Both models will share a set of input 'biometric' features. These must be things the user is likely to know about themselves. People probably know their weight and age, but probably don't know their VO2 max.\n",
    "\n",
    "The models will differ in one of their input features and their output:\n",
    "\n",
    "1. `calorie_model` needs to take workout duration + biometrics as input features and predict calories burned.\n",
    "2. `time_model` needs to take calories burned + biometrics as input features and predict workout duration. \n",
    "\n",
    "We will use dictionaries to keep everything organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59769762",
   "metadata": {},
   "outputs": [],
   "source": [
    "biometric_features=[\n",
    "    'Age', 'Gender', 'Height (cm)', 'Weight (kg)', 'Workout Type',\n",
    "    'Sleep Hours', 'Mood Before Workout'\n",
    "\n",
    "]\n",
    "\n",
    "input_features={\n",
    "    'calorie_model': ['Workout Duration (mins)'] + biometric_features,\n",
    "    'time_model': ['Calories Burned'] + biometric_features\n",
    "}\n",
    "\n",
    "output_features={\n",
    "    'calorie_model': 'Calories Burned',\n",
    "    'time_model': 'Workout Duration (mins)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620fd11",
   "metadata": {},
   "source": [
    "## 3. Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf068d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID  Age  Gender  Height (cm)  Weight (kg)  Workout Type  \\\n",
      "0        1   39     0.0          175           99           0.0   \n",
      "1        2   36     1.0          157          112           1.0   \n",
      "2        3   25     2.0          180           66           2.0   \n",
      "3        4   56     0.0          154           89           0.0   \n",
      "4        5   53     1.0          194           59           3.0   \n",
      "\n",
      "   Workout Duration (mins)  Calories Burned  Heart Rate (bpm)  Steps Taken  \\\n",
      "0                       79              384               112         8850   \n",
      "1                       73              612               168         2821   \n",
      "2                       27              540               133        18898   \n",
      "3                       39              672               118        14102   \n",
      "4                       56              410               170        16518   \n",
      "\n",
      "   Distance (km)  Workout Intensity  Sleep Hours  Water Intake (liters)  \\\n",
      "0          14.44                0.0          8.2                    1.9   \n",
      "1           1.10                0.0          8.6                    1.9   \n",
      "2           7.28                0.0          9.8                    1.9   \n",
      "3           6.55                1.0          5.8                    1.9   \n",
      "4           3.17                1.0          7.3                    1.9   \n",
      "\n",
      "   Daily Calories Intake  Resting Heart Rate (bpm)  VO2 Max  Body Fat (%)  \\\n",
      "0                   3195                        61     38.4          28.5   \n",
      "1                   2541                        73     38.4          28.5   \n",
      "2                   3362                        80     38.4          28.5   \n",
      "3                   2071                        65     38.4          28.5   \n",
      "4                   3298                        59     38.4          28.5   \n",
      "\n",
      "   Mood Before Workout Mood After Workout  \n",
      "0                  0.0           Fatigued  \n",
      "1                  1.0          Energized  \n",
      "2                  1.0           Fatigued  \n",
      "3                  2.0            Neutral  \n",
      "4                  3.0          Energized  \n"
     ]
    }
   ],
   "source": [
    "# Your code here... I recommend sklearn's OrdinalEncoder to start with because it will let us keep the \n",
    "# number/names of features constant. We can experiment with improving encoding later if we have time.\n",
    "\n",
    "categorical_features=['Gender', 'Workout Type', 'Workout Intensity', 'Mood Before Workout']\n",
    "\n",
    "# Extract unique values from categorical features\n",
    "categories_list = [\n",
    "    data_df[\"Gender\"].unique().tolist(),\n",
    "    data_df[\"Workout Type\"].unique().tolist(),\n",
    "    data_df[\"Workout Intensity\"].unique().tolist(),\n",
    "    data_df[\"Mood Before Workout\"].unique().tolist()\n",
    "]\n",
    "\n",
    "# Apply dynamic categories to OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=categories_list)\n",
    "\n",
    "# Apply encoding to categorical columns\n",
    "df_encoded = data_df.copy()  # Keep original dataframe\n",
    "df_encoded[categorical_features] = encoder.fit_transform(data_df[categorical_features])\n",
    "\n",
    "print(df_encoded.head())  # Check encoded values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a7f42",
   "metadata": {},
   "source": [
    "## 4. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943ad6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (8000, 20)\n",
      "Test Data Shape: (2000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Your code here....\n",
    "def split_data(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"Splits the dataset into train_df and test_df.\"\"\"\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Apply the split\n",
    "train_df, test_df = split_data(df_encoded)\n",
    "\n",
    "# Confirm the split sizes\n",
    "print(f\"Train Data Shape: {train_df.shape}\")\n",
    "print(f\"Test Data Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75ad5d",
   "metadata": {},
   "source": [
    "## 5. Save assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbc6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature information\n",
    "with open('../data/biometric_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(biometric_features, output_file)\n",
    "\n",
    "with open('../data/input_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(input_features, output_file)\n",
    "\n",
    "with open('../data/output_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(output_features, output_file)\n",
    "\n",
    "with open('../data/categorical_features.pkl', 'wb') as output_file:\n",
    "    pickle.dump(categorical_features, output_file)\n",
    "\n",
    "# Data\n",
    "Path('../data/processed').mkdir(exist_ok=True)\n",
    "\n",
    "with open('../data/processed/all.pkl', 'wb') as output_file:\n",
    "    pickle.dump(data_df, output_file)\n",
    "\n",
    "with open('../data/processed/train.pkl', 'wb') as output_file:\n",
    "    pickle.dump(train_df, output_file)\n",
    "\n",
    "with open('../data/processed/test.pkl', 'wb') as output_file:\n",
    "    pickle.dump(test_df, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
